{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Calculate distance from home function\n",
    "def calculate_distance(row):\n",
    "    home_location = (row['lat'], row['long'])\n",
    "    merch_location = (row['merch_lat'], row['merch_long'])\n",
    "    return geodesic(home_location, merch_location).miles\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance2(row1, row2):\n",
    "    point1 = (row1['lat'], row1['long'])\n",
    "    point2 = (row2['lat'], row2['long'])\n",
    "    return geodesic(point1, point2).miles\n",
    "\n",
    "def calculate_similarity_score(amount, fraud_mean, fraud_std, normal_mean, normal_std):\n",
    "    # Calculate Z-scores for fraud and normal\n",
    "    z_score_fraud = abs((amount - fraud_mean) / fraud_std)\n",
    "    z_score_normal = abs((amount - normal_mean) / normal_std)\n",
    "    \n",
    "    # Invert the Z-scores to get similarity scores\n",
    "    fraud_similarity = 1 / (1 + z_score_fraud)\n",
    "    normal_similarity = 1 / (1 + z_score_normal)\n",
    "    \n",
    "    return fraud_similarity, normal_similarity\n",
    "\n",
    "def process(df):\n",
    "    # Add new features\n",
    "    # Rearrange the rows\n",
    "    df['original_order'] = range(df.shape[0])\n",
    "\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%d/%m/%Y %H:%M')\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='%d/%m/%Y')\n",
    "\n",
    "    df.sort_values(by=['cc_num', 'trans_date_trans_time'], inplace=True)\n",
    "    \n",
    "    # Calculate the time difference between transactions\n",
    "    df['Time_Delta'] = df.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds() / 60.0  # Time delta in minutes\n",
    "    df['Time_Delta'] = df['Time_Delta'].fillna(value=0)\n",
    "\n",
    "    # Calculate the rolling count of transactions for each card\n",
    "    df['timestamp'] = pd.to_datetime(df['trans_date_trans_time'], format='%d/%m/%Y %H:%M')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df['rolling_trans_freq'] = df.groupby('cc_num')['trans_date_trans_time'].rolling(window='12h').count().reset_index(0, drop=True)\n",
    "    df['rolling_trans_freq'] = df['rolling_trans_freq'].fillna(value=0)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Shift the latitude and longitude to get the previous transaction's location\n",
    "    df['prev_lat'] = df.groupby('cc_num')['merch_lat'].shift(1)\n",
    "    df['prev_long'] = df.groupby('cc_num')['merch_long'].shift(1)\n",
    "\n",
    "    # Calculate the distance to the previous transaction\n",
    "    df['distance_to_prev'] = df.apply(\n",
    "        lambda row: calculate_distance2(\n",
    "            {'lat': row['merch_lat'], 'long': row['merch_long']},\n",
    "            {'lat': row['prev_lat'], 'long': row['prev_long']}\n",
    "        ) if not pd.isnull(row['prev_lat']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df['distance_to_prev'] = df['distance_to_prev'].fillna(value=0)\n",
    "\n",
    "    # Calculate location consistency as the inverse of the average distance to previous transactions (higher value means more consistency)\n",
    "    df['location_consistency'] = 100 / df.groupby('cc_num')['distance_to_prev'].transform('mean')\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "    df['month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['day_of_month'] = df['trans_date_trans_time'].dt.day\n",
    "   \n",
    "    # Age of the account holder\n",
    "    df['age'] = (df['trans_date_trans_time'] - df['dob']).dt.days // 365\n",
    "\n",
    "    df['dist_to_home'] = df.apply(calculate_distance, axis=1)\n",
    "\n",
    "    # Simple approach: Mark transactions as recurring if the same user has made transactions with the same merchant at least 3 times\n",
    "    recurring_trans = df.groupby(['cc_num', 'merchant']).filter(lambda x: len(x) >= 3)\n",
    "    recurring_trans_ids = recurring_trans['Id'].unique()\n",
    "    df['recurring_trans_indicator'] = df['Id'].apply(lambda x: 1 if x in recurring_trans_ids else 0)\n",
    "\n",
    "    # Group by category and calculate the mean and standard deviation of transaction amounts\n",
    "    category_stats = df.groupby('category')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(category_stats, on='category', how='left')\n",
    "    # Calculate z-score for each transaction amount within its category\n",
    "    df['amt_anomaly_score_cat'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "    # Group by merchant and calculate the mean and standard deviation of transaction amounts\n",
    "    merchant_stats = df.groupby('merchant')['amt'].agg(['mean', 'std']).reset_index()\n",
    "    # Merge these stats back into the main dataframe\n",
    "    df = df.merge(merchant_stats, on='merchant', how='left')\n",
    "    # Calculate z-score for each transaction amount within its merchant\n",
    "    df['amt_anomaly_score_merch'] = ((df['amt'] - df['mean']) / df['std'])\n",
    "    df.drop(columns=['mean', 'std'], inplace=True)\n",
    "\n",
    "    # Calculate the historical average transaction amount for each user\n",
    "    avg_amt_per_user = df.groupby('cc_num')['amt'].transform('mean').rename('avg_amt_per_user')\n",
    "\n",
    "    # Append this feature to the dataset\n",
    "    df['amt_relative_avg'] = (abs(df['amt'] - avg_amt_per_user) / avg_amt_per_user)\n",
    "\n",
    "    user_avg_amt = df.groupby('cc_num')['amt'].mean().reset_index(name='Avg_Amt')\n",
    "\n",
    "    df = df.merge(user_avg_amt, on='cc_num')\n",
    "\n",
    "    kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "\n",
    "    # Create a new column for the cluster labels\n",
    "    df['city_pop_cluster'] = kmeans.fit_predict(df[['city_pop']])\n",
    "\n",
    "    # Transaction frequency per card number\n",
    "    freq_per_cc = df.groupby('cc_num').size().reset_index().rename(columns={0: 'freq_per_cc'})\n",
    "    df = df.merge(freq_per_cc, on='cc_num', how='left')\n",
    "\n",
    "    # Calculate the total number of transactions per merchant per card\n",
    "    merchant_freq = df.groupby(['cc_num', 'merchant']).size().reset_index(name='merchant_trans_count')\n",
    "    # Merge this back into the main dataframe\n",
    "    df = df.merge(merchant_freq, on=['cc_num', 'merchant'], how='left')\n",
    "    df['merchant_trans_count'] = df['merchant_trans_count'].fillna(value=0)\n",
    "\n",
    "    df.drop(columns=['trans_date_trans_time', 'lat', 'long', 'merch_lat', 'merch_long'], inplace=True)\n",
    "    df.drop(columns=['prev_lat', 'prev_long', 'timestamp'], inplace=True)\n",
    "\n",
    "    # Calculate the fraud rate by category\n",
    "    fraud_rate_by_category = df.groupby('category')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_category.rename(columns={'is_fraud': 'fraud_rate_cat'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_category[['category', 'fraud_rate_cat']], on='category', how='left')\n",
    "\n",
    "    # Calculate the fraud rate by merchant\n",
    "    fraud_rate_by_merchant = df.groupby('merchant')['is_fraud'].mean().reset_index()\n",
    "    fraud_rate_by_merchant.rename(columns={'is_fraud': 'fraud_rate_merch'}, inplace=True)\n",
    "\n",
    "    # Merge the fraud rate back into the main DataFrame\n",
    "    df = pd.merge(df, fraud_rate_by_merchant[['merchant', 'fraud_rate_merch']], on='merchant', how='left')\n",
    "\n",
    "    # Separate the transactions\n",
    "    fraud_trans = df[df['is_fraud'] == 1]['amt']\n",
    "    normal_trans = df[df['is_fraud'] == 0]['amt']\n",
    "\n",
    "    # Calculate statistics\n",
    "    fraud_mean, fraud_std = fraud_trans.mean(), fraud_trans.std()\n",
    "    normal_mean, normal_std = normal_trans.mean(), normal_trans.std()\n",
    "\n",
    "    v_calculate_similarity_score = np.vectorize(calculate_similarity_score)\n",
    "\n",
    "    # Apply the function\n",
    "    df['fraud_similarity'], df['normal_similarity'] = v_calculate_similarity_score(\n",
    "        df['amt'],\n",
    "        fraud_mean, fraud_std,\n",
    "        normal_mean, normal_std\n",
    "    )\n",
    "\n",
    "    # Identify categorical columns to encode\n",
    "    categorical_cols = ['merchant', 'category', 'gender', 'city', 'state', 'job', 'cc_num']\n",
    "\n",
    "    mappings = {}\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        mappings[col] = {label: index for index, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "    # Sort the dataset back to its original order\n",
    "    df.sort_values(by='original_order', inplace=True)\n",
    "    df.drop(columns='original_order', inplace=True)\n",
    "\n",
    "    return df, mappings\n",
    "\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "train_processed, cat_map = process(trainingSet)\n",
    "train_processed.drop(columns=['first', 'last', 'street', 'dob', 'zip', 'trans_num', 'unix_time'], inplace=True)\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "test_df = pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "test_df = test_df.drop(columns=['is_fraud_x'])\n",
    "test_df = test_df.rename(columns={'is_fraud_y': 'is_fraud'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "train_df = train_processed[train_processed['is_fraud'].notnull()]\n",
    "\n",
    "# Save the datasets with the new features for easy access later\n",
    "# test_df.to_csv(\"./data/processed_test3.csv\", index=False)\n",
    "# train_df.to_csv(\"./data/processed_train3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming 'train_df' includes both features and the target ('is_fraud')\n",
    "#X = train_df.drop(['is_fraud', 'Id', 'city_pop_cluster', 'job', 'city', 'state'], axis=1)\n",
    "X = train_df.drop(['is_fraud', 'Id', 'city_pop_cluster', 'cc_num'], axis=1)\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "num_cols = ['amt', 'Time_Delta', 'distance_to_prev', 'location_consistency', 'dist_to_home', 'amt_anomaly_score_cat', 'amt_anomaly_score_merch', 'amt_relative_avg', 'fraud_rate_cat', 'fraud_rate_merch', 'fraud_similarity', 'normal_similarity', 'Avg_Amt', 'age', 'freq_per_cc', 'merchant_trans_count', 'city_pop']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        merchant  category        amt  gender  city  state  city_pop  job  \\\n",
      "459661        43         2   0.018542       1   380     17 -0.066856  163   \n",
      "517764       153         2  -0.208745       1   354      5 -0.291105   92   \n",
      "236842         9        13  -0.432193       1   684     42  5.003367  248   \n",
      "227585       572         4   0.458846       0   385      9 -0.288965  296   \n",
      "285211       189        11  10.576690       0   102     39 -0.287531  410   \n",
      "\n",
      "        Time_Delta  rolling_trans_freq  ...  amt_anomaly_score_cat  \\\n",
      "459661   -0.232477                 4.0  ...               0.545540   \n",
      "517764   -0.542272                 2.0  ...              -1.702511   \n",
      "236842   -0.531537                 3.0  ...              -0.184942   \n",
      "227585    1.178471                 1.0  ...               0.488897   \n",
      "285211   -0.382774                 7.0  ...               6.921294   \n",
      "\n",
      "        amt_anomaly_score_merch  amt_relative_avg   Avg_Amt  freq_per_cc  \\\n",
      "459661                 0.515202         -0.302675 -0.519218    -0.380424   \n",
      "517764                -1.644960         -0.199284 -0.366460    -1.127902   \n",
      "236842                -0.222472          0.072250 -1.532767     0.841924   \n",
      "227585                 0.528154          0.283106 -0.546834    -1.652603   \n",
      "285211                 8.076743         12.890694 -0.377109     1.014870   \n",
      "\n",
      "        merchant_trans_count  fraud_rate_cat  fraud_rate_merch  \\\n",
      "459661              1.974787       -0.315181         -0.655076   \n",
      "517764              2.713339       -0.315181         -0.427971   \n",
      "236842              0.497683       -0.379111         -0.109391   \n",
      "227585             -0.240868        1.476209          1.135812   \n",
      "285211              0.497683        2.295184          0.822561   \n",
      "\n",
      "        fraud_similarity  normal_similarity  \n",
      "459661          0.031986           1.325689  \n",
      "517764         -0.304603           0.333311  \n",
      "236842         -0.610209          -0.620085  \n",
      "227585          0.771000          -0.791377  \n",
      "285211         -3.857814          -5.009489  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088319088319088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.98      0.85      0.91       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.99      0.93      0.95     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "# Initialize the XGBClassifier\n",
    "xgb_clf = XGBClassifier(colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=900, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_xgb))\n",
    "print(classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9067431850789096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.98      0.84      0.91       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.99      0.92      0.95     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer\n",
    "# Initialize the XGBClassifier\n",
    "xgb_clf2 = XGBClassifier(colsample_bytree=0.9, learning_rate=0.15, max_depth=None, n_estimators=900, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "xgb_clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_clf2.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_xgb))\n",
    "print(classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343023255813954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     96876\n",
      "         1.0       0.92      0.77      0.83       375\n",
      "\n",
      "    accuracy                           1.00     97251\n",
      "   macro avg       0.96      0.88      0.92     97251\n",
      "weighted avg       1.00      1.00      1.00     97251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Create a VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "rf1 = RandomForestClassifier(class_weight='balanced_subsample', n_estimators=300, max_depth=None, min_samples_split=10, min_samples_leaf=4, criterion='entropy', n_jobs=-1, random_state=42)\n",
    "\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf1 = rf1.predict(X_val)\n",
    "print(f1_score(y_val, y_pred_rf1))\n",
    "print(classification_report(y_val, y_pred_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Create a VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf1', rf1), ('xgb2', xgb_clf2)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "vot_clf = voting_clf.fit(X, y)\n",
    "\n",
    "# # Evaluate the model\n",
    "# scores = cross_val_score(voting_clf, X, y, cv=5, scoring='f1_micro', n_jobs=-1, verbose=3)\n",
    "# print(\"F1 Score: \", scores.mean())\n",
    "y_pred_vote = vot_clf.predict(X_val)\n",
    "f1_score_vote = f1_score(y_val, y_pred_vote)\n",
    "print(f1_score_vote)\n",
    "\n",
    "# with open('best_vote_model.obj', 'wb') as f:\n",
    "#     pickle.dump(vot_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle Submission\n",
    "pred = test_df.drop(['is_fraud', 'city_pop_cluster', 'Id', 'cc_num'], axis=1)\n",
    "pred2 = test_df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "pred2['is_fraud'] = vot_clf.predict(pred)\n",
    "pred2.is_fraud = pred2.is_fraud.astype(int)\n",
    "submission = pred2[['Id', 'is_fraud']]\n",
    "submission.to_csv(\"./data/submission12.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
